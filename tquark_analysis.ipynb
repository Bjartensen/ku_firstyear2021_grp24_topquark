{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top quark analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install --upgrade --user pip\n",
    "#!{sys.executable} -m pip install uproot3 pandas numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot3 # for reading .root files\n",
    "import pandas as pd # to store data as dataframe\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import decimal\n",
    "from itertools import combinations \n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from matplotlib.ticker import AutoMinorLocator # for minor ticks\n",
    "from datetime import date\n",
    "from scipy.optimize import curve_fit\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "\n",
    "BIGGER_SIZE = 16\n",
    "plt.rc('font', size=BIGGER_SIZE)\n",
    "plt.rcParams['figure.figsize'] = [12,8]\n",
    "#plt.style.use('default')\n",
    "\n",
    "import infofile # local file containing cross-sections, sums of weights, dataset IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lumi = 0.5 # fb-1 # data_A only\n",
    "#lumi = 1.9 # fb-1 # data_B only\n",
    "#lumi = 2.9 # fb-1 # data_C only\n",
    "#lumi = 4.7 # fb-1 # data_D only\n",
    "lumi = 10 # fb-1 # data_A,data_B,data_C,data_D\n",
    "\n",
    "#fraction = 0.01 # reduce this is you want the code to run quicker\n",
    "fraction = 1.0 # reduce this is you want the code to run quicker\n",
    "                                                                                                                                  \n",
    "#tuple_path = r'C:\\Users\\jacob\\Desktop\\1lep/' # local\n",
    "tuple_path = '../data/'\n",
    "#tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/4lep/\" # web address\n",
    "\n",
    "MV2c10_cut = 0.8244\n",
    "GeV_cut = 30*1000\n",
    "ALL = slice(None) # trick til at give en query der giver alle rÃ¦kker\n",
    "W_boson = 80.385\n",
    "fig_ver = '_'+date.today().strftime(\"%d%m%Y\")+'.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\n",
    "\n",
    "    'data': {\n",
    "        'list' : ['data_A','data_B','data_C','data_D'],\n",
    "    },\n",
    "\n",
    "    r'V+jets' : { # V+jets\n",
    "        'list' : [\n",
    "\n",
    "# ls | grep \"36110[6-8]\" | grep Z\n",
    "'Zee'\n",
    ",'Zmumu'\n",
    ",'Ztautau'\n",
    "\n",
    "# ls | grep \"36110[0-5]\" | grep W\n",
    ",'Wplusenu'\n",
    ",'Wplusmunu'\n",
    ",'Wplustaunu'\n",
    ",'Wminusenu'\n",
    ",'Wminusmunu'\n",
    ",'Wminustaunu'\n",
    "\n",
    "# ls | grep \"3641[0-9][0-9]\" | grep W      \n",
    ",'Wmunu_PTV0_70_CVetoBVeto'\n",
    ",'Wmunu_PTV0_70_CFilterBVeto'\n",
    ",'Wmunu_PTV0_70_BFilter'\n",
    ",'Wmunu_PTV70_140_CVetoBVeto'\n",
    ",'Wmunu_PTV70_140_CFilterBVeto'\n",
    ",'Wmunu_PTV70_140_BFilter'\n",
    ",'Wmunu_PTV140_280_CVetoBVeto'\n",
    ",'Wmunu_PTV140_280_CFilterBVeto'\n",
    ",'Wmunu_PTV140_280_BFilter'\n",
    ",'Wmunu_PTV280_500_CVetoBVeto'\n",
    ",'Wmunu_PTV280_500_CFilterBVeto'\n",
    ",'Wmunu_PTV280_500_BFilter'\n",
    ",'Wmunu_PTV500_1000'\n",
    ",'Wmunu_PTV1000_E_CMS'\n",
    ",'Wenu_PTV0_70_CVetoBVeto'\n",
    ",'Wenu_PTV0_70_CFilterBVeto'\n",
    ",'Wenu_PTV0_70_BFilter'\n",
    ",'Wenu_PTV70_140_CVetoBVeto'\n",
    ",'Wenu_PTV70_140_CFilterBVeto'\n",
    ",'Wenu_PTV70_140_BFilter'\n",
    ",'Wenu_PTV140_280_CVetoBVeto'\n",
    ",'Wenu_PTV140_280_CFilterBVeto'\n",
    ",'Wenu_PTV140_280_BFilter'\n",
    ",'Wenu_PTV280_500_CVetoBVeto'\n",
    ",'Wenu_PTV280_500_CFilterBVeto'\n",
    ",'Wenu_PTV280_500_BFilter'\n",
    ",'Wenu_PTV500_1000'\n",
    ",'Wenu_PTV1000_E_CMS'\n",
    ",'Wtaunu_PTV0_70_CVetoBVeto'\n",
    ",'Wtaunu_PTV0_70_CFilterBVeto'\n",
    ",'Wtaunu_PTV0_70_BFilter'\n",
    ",'Wtaunu_PTV70_140_CVetoBVeto'\n",
    ",'Wtaunu_PTV70_140_CFilterBVeto'\n",
    ",'Wtaunu_PTV70_140_BFilter'\n",
    ",'Wtaunu_PTV140_280_CVetoBVeto'\n",
    ",'Wtaunu_PTV140_280_CFilterBVeto'\n",
    ",'Wtaunu_PTV140_280_BFilter'\n",
    ",'Wtaunu_PTV280_500_CVetoBVeto'\n",
    ",'Wtaunu_PTV280_500_CFilterBVeto'\n",
    ",'Wtaunu_PTV280_500_BFilter'\n",
    ",'Wtaunu_PTV500_1000'\n",
    ",'Wtaunu_PTV1000_E_CMS'\n",
    "\n",
    "# ls | grep \"3641[0-9][0-9]\" | grep Z\n",
    ",'Zmumu_PTV0_70_CVetoBVeto'\n",
    ",'Zmumu_PTV0_70_CFilterBVeto'\n",
    ",'Zmumu_PTV0_70_BFilter'\n",
    ",'Zmumu_PTV70_140_CVetoBVeto'\n",
    ",'Zmumu_PTV70_140_CFilterBVeto'\n",
    ",'Zmumu_PTV70_140_BFilter'\n",
    ",'Zmumu_PTV140_280_CVetoBVeto'\n",
    ",'Zmumu_PTV140_280_CFilterBVeto'\n",
    ",'Zmumu_PTV140_280_BFilter'\n",
    ",'Zmumu_PTV280_500_CVetoBVeto'\n",
    ",'Zmumu_PTV280_500_CFilterBVeto'\n",
    ",'Zmumu_PTV280_500_BFilter'\n",
    ",'Zmumu_PTV500_1000'\n",
    ",'Zmumu_PTV1000_E_CMS'\n",
    ",'Zee_PTV0_70_CVetoBVeto'\n",
    ",'Zee_PTV0_70_CFilterBVeto'\n",
    ",'Zee_PTV0_70_BFilter'\n",
    ",'Zee_PTV70_140_CVetoBVeto'\n",
    ",'Zee_PTV70_140_CFilterBVeto'\n",
    ",'Zee_PTV70_140_BFilter'\n",
    ",'Zee_PTV140_280_CVetoBVeto'\n",
    ",'Zee_PTV140_280_CFilterBVeto'\n",
    ",'Zee_PTV140_280_BFilter'\n",
    ",'Zee_PTV280_500_CVetoBVeto'\n",
    ",'Zee_PTV280_500_CFilterBVeto'\n",
    ",'Zee_PTV280_500_BFilter'\n",
    ",'Zee_PTV500_1000'\n",
    ",'Zee_PTV1000_E_CMS'\n",
    ",'Ztautau_PTV0_70_CVetoBVeto'\n",
    ",'Ztautau_PTV0_70_CFilterBVeto'\n",
    ",'Ztautau_PTV0_70_BFilter'\n",
    ",'Ztautau_PTV70_140_CVetoBVeto'\n",
    ",'Ztautau_PTV70_140_CFilterBVeto'\n",
    ",'Ztautau_PTV70_140_BFilter'\n",
    ",'Ztautau_PTV140_280_CVetoBVeto'\n",
    ",'Ztautau_PTV140_280_CFilterBVeto'\n",
    ",'Ztautau_PTV140_280_BFilter'\n",
    ",'Ztautau_PTV280_500_CVetoBVeto'\n",
    ",'Ztautau_PTV280_500_CFilterBVeto'\n",
    ",'Ztautau_PTV280_500_BFilter'\n",
    ",'Ztautau_PTV500_1000'\n",
    ",'Ztautau_PTV1000_E_CMS'\n",
    "        ],\n",
    "        'color' : \"#ff0000\" # red\n",
    "    },\n",
    "\n",
    "    r'Single top' : { # Single top\n",
    "        'list' : [\n",
    "# ls | grep \"410011\\|410012\\|410013\\|410014\\|410025\\|410026\"\n",
    "'single_top_tchan'\n",
    ",'single_antitop_tchan'\n",
    ",'single_top_wtchan'\n",
    ",'single_antitop_wtchan'\n",
    ",'single_top_schan'\n",
    ",'single_antitop_schan'\n",
    "        ],\n",
    "        'color' : \"#00cdff\" # light blue\n",
    "    },\n",
    "    \n",
    "    r'Diboson' : { # Diboson\n",
    "        # ls | grep \"363359\\|363360\\|363492\\|363356\\|363490\\|363358\\|363489\\|363491\\|363493\"\n",
    "        'list' : ['ZqqZll','WqqZll','WpqqWmlv','WplvWmqq','WlvZqq','llll','lllv','llvv','lvvv'],\n",
    "        'color' : \"#00ff32\" # green\n",
    "    },\n",
    "\n",
    "    r'$t\\bar{t}$' : { # ttbar\n",
    "        'list' : ['ttbar_lep'],\n",
    "        'color' : \"#6b59d3\" # purple\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_err(p_num):\n",
    "    return np.format_float_positional(p_num, precision=1, unique=False, fractional=False, trim='-')\n",
    "\n",
    "def guess_precision(p_decimal):\n",
    "    if p_decimal >= 1:\n",
    "        return 0\n",
    "    else:\n",
    "        return abs(decimal.Decimal(fmt_err(p_decimal)).as_tuple().exponent)\n",
    "\n",
    "def fmt_res(p_num, p_err = 0.01):\n",
    "    m_precision = guess_precision(p_err)\n",
    "    return np.format_float_positional(p_num, precision=m_precision, unique=False, fractional=True, trim='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_files():\n",
    "    data = {} # define empty dictionary to hold dataframes\n",
    "    for s in samples: # loop over samples\n",
    "        print('Processing '+s+' samples') # print which sample\n",
    "        tasks = []\n",
    "        frames = [] # define empty list to hold data\n",
    "        for val in samples[s]['list']: # loop over each file\n",
    "            if s == 'data': prefix = \"Data/\" # Data prefix\n",
    "            else: # MC prefix\n",
    "                prefix = \"MC/mc_\"+str(infofile.infos[val][\"DSID\"])+\".\"\n",
    "            fileString = tuple_path+prefix+val+\".1lep.root\" # file name to open\n",
    "            tasks.append((fileString, val))\n",
    "        with Pool(os.cpu_count()) as p:\n",
    "            frames = p.starmap(read_file, tasks)\n",
    "            data[s] = pd.concat(frames) # dictionary entry is concatenated dataframes\n",
    "\n",
    "    return data # return dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(xsec_weight, mcWeight, scaleFactor_PILEUP,\n",
    "                scaleFactor_ELE, scaleFactor_MUON, \n",
    "                scaleFactor_LepTRIGGER ):\n",
    "    return xsec_weight*mcWeight*scaleFactor_PILEUP*scaleFactor_ELE*scaleFactor_MUON*scaleFactor_LepTRIGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xsec_weight(sample):\n",
    "    info = infofile.infos[sample] # open infofile\n",
    "    xsec_weight = (lumi*1000*info[\"xsec\"])/(info[\"sumw\"]*info[\"red_eff\"]) #*1000 to go from fb-1 to pb-1\n",
    "    return xsec_weight # return cross-section weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mjjj(jet_pt,jet_eta,jet_phi,jet_E):\n",
    "    px_0 = jet_pt[0]*math.cos(jet_phi[0]) # x-component of lep[0] momentum\n",
    "    py_0 = jet_pt[0]*math.sin(jet_phi[0]) # y-component of lep[0] momentum\n",
    "    pz_0 = jet_pt[0]*math.sinh(jet_eta[0]) # z-component of lep[0] momentum\n",
    "    px_1 = jet_pt[1]*math.cos(jet_phi[1]) # x-component of lep[1] momentum\n",
    "    py_1 = jet_pt[1]*math.sin(jet_phi[1]) # y-component of lep[1] momentum\n",
    "    pz_1 = jet_pt[1]*math.sinh(jet_eta[1]) # z-component of lep[1] momentum\n",
    "    px_2 = jet_pt[2]*math.cos(jet_phi[2]) # x-component of lep[2] momentum\n",
    "    py_2 = jet_pt[2]*math.sin(jet_phi[2]) # y-component of lep[2] momentum\n",
    "    pz_2 = jet_pt[2]*math.sinh(jet_eta[2]) # z-component of lep[3] momentum\n",
    "    sumpx = px_0 + px_1 + px_2 # x-component of 4-jets\n",
    "    sumpy = py_0 + py_1 + py_2 # y-component of 4 jets\n",
    "    sumpz = pz_0 + pz_1 + pz_2 # z-component of 4 jets\n",
    "    sumE = jet_E[0] + jet_E[1] + jet_E[2] # energy of 4 jets\n",
    "    jjj_pt = (px_0+px_1+px_2)**2+(py_0+py_1+py_2)**2\n",
    "    jjj_m = math.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV\n",
    "    return jjj_pt, jjj_m\n",
    "\n",
    "def calc_mjj(jet_pt,jet_eta,jet_phi,jet_E):\n",
    "    px_0 = jet_pt[0]*math.cos(jet_phi[0]) # x-component of lep[0] momentum\n",
    "    py_0 = jet_pt[0]*math.sin(jet_phi[0]) # y-component of lep[0] momentum\n",
    "    pz_0 = jet_pt[0]*math.sinh(jet_eta[0]) # z-component of lep[0] momentum\n",
    "    px_1 = jet_pt[1]*math.cos(jet_phi[1]) # x-component of lep[1] momentum\n",
    "    py_1 = jet_pt[1]*math.sin(jet_phi[1]) # y-component of lep[1] momentum\n",
    "    pz_1 = jet_pt[1]*math.sinh(jet_eta[1]) # z-component of lep[1] momentum\n",
    "    sumpx = px_0 + px_1# x-component of 2 jets\n",
    "    sumpy = py_0 + py_1# y-component of 2 jets\n",
    "    sumpz = pz_0 + pz_1# z-component of 2 jets\n",
    "    sumE = jet_E[0] + jet_E[1]# energy of 2 jets\n",
    "    jj_m = math.sqrt(sumE**2 - sumpx**2 - sumpy**2 - sumpz**2)/1000 #/1000 to go from MeV to GeV\n",
    "    return jj_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tjekker om der kun er Ã©n b-tagget i en kombination\n",
    "def en_btag_tjek(data):\n",
    "    filtered = list(filter(lambda d: d[0] > MV2c10_cut, data))\n",
    "    return len(filtered) == 1\n",
    "\n",
    "def to_ikke_btag_tjek(data):\n",
    "    filtered = list(filter(lambda d: d[0] > MV2c10_cut, data))\n",
    "    return len(filtered) == 0\n",
    "\n",
    "def mjjj_bedste(jet_MV2c10, jet_pt, jet_eta, jet_phi, jet_E):\n",
    "    try:\n",
    "        samlet = zip(jet_MV2c10, jet_pt, jet_eta, jet_phi, jet_E)\n",
    "        comb = combinations(samlet, 3) # laver alle kombinationer\n",
    "        en_btagget_comb = list(filter(en_btag_tjek, comb)) # laver liste med rigtige komb. liste med tre tupler\n",
    "        liste_pt_m = []\n",
    "        for jets in en_btagget_comb:\n",
    "            z = list(zip(*jets))  # laver fem lister med tre vÃ¦rdier i hver liste\n",
    "            pt, m = calc_mjjj(z[1],z[2],z[3],z[4])\n",
    "            liste_pt_m.append((pt,m))\n",
    "        liste_pt, liste_m = list(zip(*liste_pt_m))\n",
    "        bedste = np.argmax(liste_pt) # hvilket index i listen har hÃ¸jest vÃ¦rdi    \n",
    "        mjjj = liste_m[bedste]\n",
    "        mW_zipped = list(zip(*[j for j in en_btagget_comb[bedste] if j[0] <= MV2c10_cut]))\n",
    "        mW = calc_mjj(mW_zipped[1],mW_zipped[2],mW_zipped[3],mW_zipped[4])\n",
    "        return mjjj, mW # slÃ¥r op og fÃ¥r vÃ¦rdien\n",
    "    except ValueError:\n",
    "        return 0,0\n",
    "\n",
    "def W_m(jet_MV2c10, jet_pt, jet_eta, jet_phi, jet_E):\n",
    "    try:\n",
    "        samlet = zip(jet_MV2c10, jet_pt, jet_eta, jet_phi, jet_E)\n",
    "        comb = combinations(samlet, 2) # laver alle kombinationer\n",
    "        to_btagget_comb = list(filter(to_ikke_btag_tjek, comb)) # laver liste med rigtige komb. liste med tre tupler\n",
    "        liste_m = []\n",
    "        for jets in to_btagget_comb:\n",
    "            z = list(zip(*jets))\n",
    "            m = calc_mjj(z[1],z[2],z[3],z[4])\n",
    "            liste_m.append(m)\n",
    "        m_diff = [abs(i-W_boson) for i in liste_m]\n",
    "        bedste = np.argmin(m_diff) # hvilket index i listen har hÃ¸jest vÃ¦rdi\n",
    "        mW = liste_m[bedste]\n",
    "        \n",
    "        W_comb = [ [[jet_MV2c10[i],jet_pt[i],jet_eta[i],jet_phi[i],jet_E[i]]] + list(to_btagget_comb[bedste]) for i,v in enumerate(jet_MV2c10) if v > MV2c10_cut ]\n",
    "        \n",
    "        mjjj_pt = []\n",
    "        mjjj_m = []\n",
    "        for i in W_comb:\n",
    "            a,b,c,d,e = list(zip(*i))\n",
    "            x,y = calc_mjjj(b,c,d,e)\n",
    "            mjjj_pt.append(x)\n",
    "            mjjj_m.append(y)\n",
    "        \n",
    "        return mjjj_m[np.argmax(mjjj_pt)], mW\n",
    "    except ValueError:\n",
    "        return 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_pt(lep_pt):\n",
    "    return lep_pt < GeV_cut\n",
    "\n",
    "def cut_jet_n(jet_n):\n",
    "    return jet_n < 4\n",
    "\n",
    "def jet_pt_30GeV(jet_pt):\n",
    "    # the jet pt is sorted by largest\n",
    "    return jet_pt[3] > GeV_cut\n",
    "\n",
    "def jet_pt_sum(jet_pt):\n",
    "    return sum(jet_pt)/1000\n",
    "\n",
    "def b_tag_70(jet_MV2c10):\n",
    "    return len([num for num in jet_MV2c10 if num > MV2c10_cut]) > 1\n",
    "\n",
    "def MT_W(lep_pt, lep_phi, met_et, met_phi):\n",
    "    return np.sqrt(2*lep_pt*met_et*(1-np.cos(lep_phi-met_phi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuts som krÃ¦ver 1 lep\n",
    "Samt 4 jets hvor 2 af jets har 70% sikkerhed\n",
    "\n",
    "find invariant masse for 3 jets sammnenlagt. (der er 2 forskellige sammensÃ¦tninger grundet 2 b jets.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path,sample):\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = pd.DataFrame() # define empty pandas DataFrame to hold all data for this sample\n",
    "    tree = uproot3.open(path)[\"mini\"] # open the tree called mini\n",
    "    numevents = uproot3.numentries(path, \"mini\") # number of events\n",
    "    \n",
    "    # variables to calculate Monte Carlo weight\n",
    "    if 'data' not in sample: xsec_weight = get_xsec_weight(sample) # get cross-section weight\n",
    "\n",
    "    root_variables = ['lep_pt','lep_phi'\n",
    "                  ,'met_et','met_phi'\n",
    "                  ,'jet_n','jet_pt','jet_eta','jet_phi','jet_E','jet_MV2c10'\n",
    "                  ,'mcWeight','scaleFactor_PILEUP','scaleFactor_ELE','scaleFactor_MUON','scaleFactor_LepTRIGGER']\n",
    "    \n",
    "    for data in tree.iterate(root_variables, outputtype=pd.DataFrame, entrystop=numevents*fraction):    \n",
    "        nIn = len(data.index) # number of events in this batch\n",
    "\n",
    "        if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "            # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "            data['totalWeight'] = np.vectorize(calc_weight)(xsec_weight,\n",
    "                                                            data.mcWeight,\n",
    "                                                            data.scaleFactor_PILEUP,\n",
    "                                                            data.scaleFactor_ELE,\n",
    "                                                            data.scaleFactor_MUON,\n",
    "                                                            data.scaleFactor_LepTRIGGER)\n",
    "    \n",
    "        # cut jet number\n",
    "        fail = data[ np.vectorize(cut_jet_n)(data.jet_n) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        # b-tag\n",
    "        data['jet_pt_30GeV'] = np.vectorize(jet_pt_30GeV)(data.jet_pt)\n",
    "\n",
    "        # cut lep pt\n",
    "        fail = data[ np.vectorize(cut_lep_pt)(data.lep_pt) ].index\n",
    "        data.drop(fail, inplace=True)\n",
    "        \n",
    "        # b-tag\n",
    "        data['b_tag'] = np.vectorize(b_tag_70)(data.jet_MV2c10)\n",
    "    \n",
    "        # Invariant mass\n",
    "        _, data['mjjj'] = np.vectorize(calc_mjjj)(data.jet_pt,data.jet_eta,data.jet_phi,data.jet_E)\n",
    "\n",
    "        data['pt_mjjj_bedste'], data['pt_mjj_comb'] = np.vectorize(mjjj_bedste)(data.jet_MV2c10,data.jet_pt,data.jet_eta,data.jet_phi,data.jet_E)\n",
    "        \n",
    "        data['W_mjjj_bedste'], data['W_mjj_comb'] = np.vectorize(W_m)(data.jet_MV2c10,data.jet_pt,data.jet_eta,data.jet_phi,data.jet_E)\n",
    "        \n",
    "        data['jet_pt_sum'] = np.vectorize(jet_pt_sum)(data.jet_pt)\n",
    "        \n",
    "        #\n",
    "        data['MT_W'] = np.vectorize(MT_W)(data.lep_pt, data.lep_phi, data.met_et, data.met_phi)\n",
    "        \n",
    "        # Clear unused columns to save memory\n",
    "        data.drop(columns=[\n",
    "            'lep_pt','lep_phi','met_phi','jet_n','jet_pt','jet_eta','jet_phi','jet_E','jet_MV2c10'\n",
    "            ,'mcWeight','scaleFactor_PILEUP','scaleFactor_ELE','scaleFactor_MUON','scaleFactor_LepTRIGGER'\n",
    "        ], inplace=True)\n",
    "        \n",
    "        nOut = len(data.index) # number of events passing cuts in this batch\n",
    "        data_all = data_all.append(data) # append dataframe from this batch to the dataframe for the whole sample\n",
    "        elapsed = time.time() - start # time taken to process\n",
    "        print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "      \n",
    "    return data_all # return dataframe containing events passing all cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time() # time at start of whole processing\n",
    "data = get_data_from_files() # process all files\n",
    "elapsed = time.time() - start # time after whole processing\n",
    "print(\"Time taken: \"+str(round(elapsed,1))+\"s\") # print total time taken to process every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x,A,mu,std):\n",
    "    y = (A*np.exp(-((x-mu)**2)/(2*std**2)))\n",
    "    return y\n",
    "\n",
    "def lin_fit(x, a, b):\n",
    "    return a*x + b\n",
    "\n",
    "def gauss_lin(x,A,mu,std,a,b):\n",
    "    return gauss(x,A,mu,std) + lin_fit(x, a, b)\n",
    "\n",
    "def plot_data_query(data, query, column, p_xmin = 100, p_xmax = 240, p_step_size = 5, p_xlabel = 'mjjj [GeV]', p_title = '', desc = '', cut_text = '',  div_plot = False, fit = False):\n",
    "\n",
    "    xmin = p_xmin # GeV\n",
    "    xmax = p_xmax # GeV\n",
    "    step_size = p_step_size # GeV\n",
    "\n",
    "    bin_edges = np.arange(start=xmin, # The interval includes this value\n",
    "                     stop=xmax+step_size, # The interval doesn't include this value\n",
    "                     step=step_size ) # Spacing between values\n",
    "    bin_centres = np.arange(start=xmin+step_size/2, # The interval includes this value\n",
    "                            stop=xmax+step_size/2, # The interval doesn't include this value\n",
    "                            step=step_size ) # Spacing between values\n",
    "\n",
    "    data_x,_ = np.histogram(data['data'].query(query)[column],\n",
    "                            bins=bin_edges ) # histogram the data\n",
    "    data_x_errors = np.sqrt( data_x ) # statistical error on the data\n",
    "\n",
    "    signal_x = data[r'$t\\bar{t}$'].query(query)[column] # histogram the signal\n",
    "    signal_weights = data[r'$t\\bar{t}$'].query(query).totalWeight # get the weights of the signal events\n",
    "    signal_color = samples[r'$t\\bar{t}$']['color'] # get the colour for the signal bar\n",
    "\n",
    "    mc_x = [] # define list to hold the Monte Carlo histogram entries\n",
    "    mc_weights = [] # define list to hold the Monte Carlo weights\n",
    "    mc_colors = [] # define list to hold the colors of the Monte Carlo bars\n",
    "    mc_labels = [] # define list to hold the legend labels of the Monte Carlo bars\n",
    "\n",
    "    for s in samples: # loop over samples\n",
    "        if s not in ['data', r'$t\\bar{t}$']: # if not data nor signal\n",
    "            mc_x.append( data[s].query(query)[column] ) # append to the list of Monte Carlo histogram entries\n",
    "            mc_weights.append( data[s].query(query).totalWeight ) # append to the list of Monte Carlo weights\n",
    "            mc_colors.append( samples[s]['color'] ) # append to the list of Monte Carlo bar colors\n",
    "            mc_labels.append( s ) # append to the list of Monte Carlo legend labels\n",
    "\n",
    "    # *************\n",
    "    # Main plot\n",
    "    # *************\n",
    "    main_axes = plt.gca() # get current axes\n",
    "\n",
    "    # plot the data points\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', # 'k' means black and 'o' is for circles\n",
    "                       label='Data')\n",
    "\n",
    "    # plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist(mc_x, bins=bin_edges,\n",
    "                                weights=mc_weights, stacked=True,\n",
    "                                color=mc_colors, label=mc_labels )\n",
    "\n",
    "    mc_x_tot = mc_heights[0][-1] # stacked background MC y-axis value\n",
    "\n",
    "    # plot the signal bar\n",
    "    mc_signal = main_axes.hist(signal_x, bins=bin_edges, bottom=mc_x_tot,\n",
    "                   weights=signal_weights, color=signal_color,\n",
    "                   label=r'$t\\bar{t}$')\n",
    "\n",
    "    mc_x_err = np.sqrt( mc_x_tot+mc_signal[0] ) # statistical error on the MC bars\n",
    "\n",
    "    # plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, # x\n",
    "                  2*mc_x_err, # heights\n",
    "                  alpha=0.5, # half transparency\n",
    "                  bottom=mc_x_tot+mc_signal[0]-mc_x_err, color='none',\n",
    "                  hatch=\"////\", width=step_size, label='Stat. Unc.' )\n",
    "\n",
    "    if fit:\n",
    "        #laver fit med gauss funktionen og giver den start gÃ¦t for at ramme et ordentligt fit.\n",
    "\n",
    "        mc_all = mc_heights[0][0]+mc_signal[0]\n",
    "        sec_min = 150\n",
    "        sec_max = 190\n",
    "        section = [ (x,data_x[i],data_x_errors[i],mc_all[i],mc_x_err[i]) for i,x in enumerate(bin_centres) if x > sec_min and x < sec_max ]\n",
    "        x_sec,y_sec,sigma_sec,mc_sec,mc_sigma_sec = zip(*section)\n",
    "\n",
    "        A = np.array(y_sec).max()\n",
    "        mu = sec_min + p_step_size*np.array(y_sec).argmax() + p_step_size/2\n",
    "        sigma = 30#np.std(data_x)#30\n",
    "        a = (np.array(y_sec)[-1]-np.array(y_sec)[0])/(sec_max - sec_min - p_step_size)\n",
    "\n",
    "        X = np.linspace(sec_min, sec_max, 100000)\n",
    "        par, cov = curve_fit(gauss, x_sec, y_sec, sigma=sigma_sec, p0=[A, mu, sigma], absolute_sigma = True)\n",
    "        plt.plot(X, gauss(X, *par), label = 'Data fit', color='Orange', linewidth=5, linestyle='dashed')\n",
    "\n",
    "        A = np.array(mc_sec).max()\n",
    "        mu = sec_min + p_step_size*np.array(mc_sec).argmax() + p_step_size/2\n",
    "        sigma = 30#np.std(data_x)#30\n",
    "        a = (np.array(mc_sec)[-1]-np.array(mc_sec)[0])/(sec_max - sec_min - p_step_size)\n",
    "        par2, cov2 = curve_fit(gauss, x_sec, mc_sec, sigma=mc_sigma_sec, p0=[A, mu, sigma], absolute_sigma = True)\n",
    "        plt.plot(X, gauss(X, *par2), label = 'MC fit', color='Red', linewidth=5, linestyle='dashed')\n",
    "\n",
    "        plt.text(0.02, # x\n",
    "                 0.74, # y\n",
    "                 'Gauss fit', # text\n",
    "                 transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "                 fontsize=BIGGER_SIZE)\n",
    "\n",
    "        plt.text(0.03, # x\n",
    "                 0.70, # y\n",
    "                 'Data $\\mu$: ' +  fmt_res(par[1], np.sqrt(cov[1][1])) + ' $\\pm$' + fmt_err(np.sqrt(cov[1][1])), # text\n",
    "                 transform=main_axes.transAxes , # coordinate system used is that of main_axes\n",
    "                 fontsize=13)\n",
    "\n",
    "        # Add a label for the analysis carried out\n",
    "        plt.text(0.03, # x\n",
    "                 0.66, # y\n",
    "                 'MC $\\mu$: ' +  fmt_res(par2[1], np.sqrt(cov2[1][1])) + ' $\\pm$' + fmt_err(np.sqrt(cov2[1][1])), # text\n",
    "                 transform=main_axes.transAxes , # coordinate system used is that of main_axes\n",
    "                 fontsize=13)\n",
    "\n",
    "\n",
    "    # set the x-limit of the main axes\n",
    "    main_axes.set_xlim( left=xmin, right=xmax )\n",
    "\n",
    "    # separation of x axis minor ticks\n",
    "    main_axes.xaxis.set_minor_locator( AutoMinorLocator() )\n",
    "\n",
    "    # set the axis tick parameters for the main axes\n",
    "    main_axes.tick_params(which='both', # ticks on both x and y axes\n",
    "                          direction='in', # Put ticks inside and outside the axes\n",
    "                          top=True, # draw ticks on the top axis\n",
    "                          right=True ) # draw ticks on right axis\n",
    "\n",
    "    # x-axis label\n",
    "    main_axes.set_xlabel(p_xlabel, fontsize=13, x=1, horizontalalignment='right')\n",
    "\n",
    "    # write y-axis label for main axes\n",
    "    main_axes.set_ylabel('Events / '+str(step_size)+' GeV',\n",
    "                         y=1, horizontalalignment='right')\n",
    "\n",
    "    # set y-axis limits for main axes\n",
    "    main_axes.set_ylim( bottom=0, top=np.amax(data_x)*1.6 )\n",
    "\n",
    "    # add minor ticks on y-axis for main axes\n",
    "    main_axes.yaxis.set_minor_locator( AutoMinorLocator() )\n",
    "\n",
    "    plt.title(p_title)\n",
    "\n",
    "    # Add text 'ATLAS Open Data' on plot\n",
    "    plt.text(0.02, # x\n",
    "             0.93, # y\n",
    "             'ATLAS Open Data', # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13 )\n",
    "\n",
    "    # Add energy and luminosity\n",
    "    lumi_used = str(lumi*fraction) # luminosity to write on the plot\n",
    "    plt.text(0.42, # x\n",
    "             0.93, # y\n",
    "             '$\\sqrt{s}$=13 TeV,$\\int$L dt = '+lumi_used+' fb$^{-1}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.62, # x\n",
    "             0.86, # y\n",
    "             r'$\\mathrm{t\\bar{t}}\\rightarrow \\mathrm{l}\\nu\\mathrm{b\\: q\\bar{q}b}$', # text\n",
    "             transform=main_axes.transAxes ) # coordinate system used is that of main_axes\n",
    "\n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.02, # x\n",
    "             0.86, # y\n",
    "             desc, # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=BIGGER_SIZE)\n",
    "\n",
    "    # Add a label for the analysis carried out\n",
    "    plt.text(0.03, # x\n",
    "             0.82, # y\n",
    "             cut_text, # text\n",
    "             transform=main_axes.transAxes, # coordinate system used is that of main_axes\n",
    "             fontsize=13)\n",
    "\n",
    "    # draw the legend\n",
    "    main_axes.legend( frameon=False ) # no box around the legend\n",
    "\n",
    "\n",
    "    #\n",
    "\n",
    "    if div_plot:\n",
    "        plt.show()\n",
    "#        plt.plot(bin_centres, data_x/(mc_x_tot+mc_signal[0]))\n",
    "        plt.hlines(y = 1, xmin = p_xmin, xmax = p_xmax)\n",
    "        plt.xlim(p_xmin,p_xmax)\n",
    "        plt.ylim(0,2)\n",
    "\n",
    "        plt.errorbar(x=bin_centres, y=data_x/(mc_x_tot+mc_signal[0]), yerr=data_x_errors/(mc_x_tot+mc_signal[0]),\n",
    "                           fmt='ko', # 'k' means black and 'o' is for circles\n",
    "                           label='Data')\n",
    "\n",
    "        plt.ylabel('Data / MC',\n",
    "                             y=1, horizontalalignment='right')\n",
    "\n",
    "        plt.xlabel(p_xlabel, fontsize=13, x=1, horizontalalignment='right')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_data_query(data, 'W_mjjj_bedste != 0', 'W_mjjj_bedste', div_plot = True, fit = True, desc = 'Bedste W boson', cut_text = 'btag true')\n",
    "#plt.show()\n",
    "#plot_data_query(data, 'pt_mjjj_bedste != 0', 'pt_mjjj_bedste', div_plot = False, fit = True, desc = 'HÃ¸jest p$_T$ af jets', cut_text = 'btag true')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Totalt antal rÃ¦kker fÃ¸r yderligere cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(data['data']) + len(data[r'V+jets']) + len(data[r'Single top']) + len(data[r'Diboson']) + len(data[r'$t\\bar{t}$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RÃ¦kkefÃ¸lge af cuts til at plotte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_cuts = 'pt_mjjj_bedste != 0 & b_tag == True & jet_pt_30GeV == True & met_et > @GeV_cut & MT_W > @GeV_cut'\n",
    "all_cuts = 'b_tag == True & jet_pt_30GeV == True & met_et > @GeV_cut & MT_W > @GeV_cut'\n",
    "all_cuts_text = 'At least two b-tagged jets & jet p$_T$, $E_{T}^{miss}$, $M_T^W$ > 30GeV'\n",
    "btag_cut = 'At least two b-tagged jets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skalarsum af pt\n",
    "\n",
    "* all\n",
    "\n",
    "* hvert enkelt cut\n",
    "\n",
    "* alle cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = 'Cuts'\n",
    "title = 'Scalar sum of jet p$_T$'\n",
    "xlabel = 'Scalar sum of jet p$_T$ [GeV]'\n",
    "xmin = 80\n",
    "xmax = 600\n",
    "step_size = 10\n",
    "plot_data_query(data, '@ALL', 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = 'No cuts', p_title = title)\n",
    "plt.savefig('pt_sum'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'b_tag == True', 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title, cut_text = 'At least two b-tagged jets')\n",
    "plt.savefig('pt_sum_btrue'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'jet_pt_30GeV == True', 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title, cut_text = 'All jet p$_T$ > 30GeV')\n",
    "plt.savefig('pt_sum_jetpt'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'met_et > @GeV_cut', 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title, cut_text = '$E_{T}^{miss}$ > 30GeV')\n",
    "plt.savefig('pt_sum_metet'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'MT_W > @GeV_cut', 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title, cut_text = '$M_T^W$ > 30GeV')\n",
    "plt.savefig('pt_sum_MTW'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'jet_pt_sum', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title, cut_text = all_cuts_text)\n",
    "plt.savefig('pt_sum_all_cuts'+fig_ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W-masserne\n",
    "\n",
    "### Highest top-quark p$_T$ combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* btag\n",
    "\n",
    "* alle cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = '$M^W$ from highest top-quark p$_T$ combination'\n",
    "title = 'W boson mass'\n",
    "xlabel = '$M^W$ [GeV]'\n",
    "step_size = 3\n",
    "xmin = 40\n",
    "xmax = 120\n",
    "plot_data_query(data, '@ALL', 'pt_mjj_comb', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title)\n",
    "plt.savefig('W_mass_pt'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'b_tag == True', 'pt_mjj_comb', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = btag_cut, p_title = title)\n",
    "plt.savefig('W_mass_pt_btag'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'pt_mjj_comb', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title)\n",
    "plt.savefig('W_mass_pt_all_cuts'+fig_ver)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bedste $M^W$ jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = '$M^W$ from best 2-jet combination'\n",
    "title = 'W boson mass'\n",
    "xlabel = '$M^W$ [GeV]'\n",
    "plot_data_query(data, '@ALL', 'W_mjj_comb', p_xmin = 40, p_xmax = 120, p_step_size = 3, p_xlabel = xlabel, desc = descr, p_title = title)\n",
    "plt.savefig('W_mass_W'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'b_tag == True', 'W_mjj_comb', p_xmin = 40, p_xmax = 120, p_step_size = 3, p_xlabel = xlabel, desc = descr, cut_text = btag_cut, p_title = title)\n",
    "plt.savefig('W_mass_W_btag'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'W_mjj_comb', p_xmin = 40, p_xmax = 120, p_step_size = 3, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title)\n",
    "plt.savefig('W_mass_W_all_cuts'+fig_ver)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-kvark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Highest top-quark p$_T$ combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"tre bedste\"\n",
    "\n",
    "* btag\n",
    "\n",
    "* alle cuts\n",
    "\n",
    "* alle cuts, fit og data/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = 'Top-quark mass from highest 3-jet p$_T$'\n",
    "title = 'Top-quark mass'\n",
    "xlabel = 'm$_{jjj}^{\\mathrm{max\\:p_{T}}}$ [GeV]'\n",
    "step_size = 3\n",
    "xmin = 100\n",
    "xmax = 250\n",
    "plot_data_query(data, '@ALL', 'pt_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title)\n",
    "plt.savefig('tquark_pt'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'b_tag == True', 'pt_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = btag_cut, p_title = title)\n",
    "plt.savefig('tquark_pt_btag'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'pt_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title)\n",
    "plt.savefig('tquark_pt_all_cuts'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'pt_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title, fit=True)\n",
    "plt.savefig('tquark_pt_all_cuts_fit'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'pt_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title, fit=True, div_plot = True)\n",
    "plt.savefig('tquark_pt_all_cuts_div'+fig_ver)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bedste $M^W$ jets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"tre bedste\"\n",
    "\n",
    "* btag\n",
    "\n",
    "* alle cuts\n",
    "\n",
    "* alle cuts, fit og data/pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = 'Top-quark mass from best $M^W$'\n",
    "title = 'Top-quark mass'\n",
    "xlabel = 'm$_{jjj}^{best\\:W}$ [GeV]'\n",
    "step_size = 3\n",
    "xmin = 100\n",
    "xmax = 250\n",
    "plot_data_query(data, '@ALL', 'W_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, p_title = title)\n",
    "plt.savefig('tquark_W'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, 'b_tag == True', 'W_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = btag_cut, p_title = title)\n",
    "plt.savefig('tquark_W_btag'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'W_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title)\n",
    "plt.savefig('tquark_W_all_cuts'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'W_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title, fit=True)\n",
    "plt.savefig('tquark_W_all_cuts_fit'+fig_ver)\n",
    "plt.show()\n",
    "plot_data_query(data, all_cuts, 'W_mjjj_bedste', p_xmin = xmin, p_xmax = xmax, p_step_size = step_size, p_xlabel = xlabel, desc = descr, cut_text = all_cuts_text, p_title = title, fit=True, div_plot = True)\n",
    "plt.savefig('tquark_W_all_cuts_div'+fig_ver)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
